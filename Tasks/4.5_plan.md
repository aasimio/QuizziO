# Task 4.5: Camera Frame Processing - Implementation Plan

## Overview
Implement the real-time camera frame pipeline inside ScannerBloc to detect ArUco markers at ~10 FPS and trigger auto-capture after 500ms of stable alignment.

## Current Code Audit (v2.3)
- `lib/core/services/camera_service.dart`:
  - Provides `imageStream` and `convertCameraImageToBytes(...)` for YUV420/BGRA.
  - Y plane for Android is handled with row padding; BGRA path copies bytes directly.
- `lib/features/omr/presentation/bloc/scanner_bloc.dart`:
  - Subscribes to `imageStream` and processes frames in `_processFrame`.
  - Uses `_isProcessingFrame` to skip concurrent processing.
  - Runs `ImagePreprocessor.preprocess` then `MarkerDetector.detect`.
  - Uses a 500ms timer to trigger `ScannerStabilityAchieved`.
- `lib/features/omr/services/image_preprocessor.dart`:
  - Builds a Mat from pixels and converts to grayscale with CLAHE.
- `lib/features/omr/services/marker_detector.dart`:
  - Detects ArUco markers (DICT_4X4_50), returns counts + confidence.
- `lib/features/omr/presentation/pages/camera_test_page.dart`:
  - Similar frame processing loop for diagnostics.

Gaps vs Task 4.5:
- No explicit 10 FPS throttle; only "skip while processing".
- Frame processing is not state-gated (could run during Capturing/Processing if stream is active).
- BGRA conversion does not account for bytesPerRow padding (verify on iOS).
- Timer can fire after marker loss if event ordering races.

## Requirements (from Development Plan)
1. Stream camera frames from CameraService into ScannerBloc.
2. Throttle to 10 FPS and skip frames if processing.
3. Convert CameraImage to Uint8List (YUV420/BGRA).
4. Call MarkerDetector.detect on the processed frame.
5. Emit marker update when all 4 markers are detected.
6. Trigger capture after 500ms of stable detection.

## Files to Modify
| File | Changes |
|------|---------|
| `lib/features/omr/presentation/bloc/scanner_bloc.dart` | Add real 10 FPS throttle, state gating, and robust stability handling |
| `lib/core/services/camera_service.dart` | Harden BGRA conversion for bytesPerRow padding |
| `lib/features/omr/services/image_preprocessor.dart` | (Optional) add input length validation or fast-path checks |
| `lib/core/constants/omr_constants.dart` | Add frame throttle + stability duration constants |
| `lib/features/omr/presentation/pages/camera_test_page.dart` | (Optional) reuse throttle helper for consistent behavior |
| `test/features/omr/presentation/bloc/scanner_bloc_test.dart` | Add tests around throttle/stability |

## Detailed Implementation Steps

### Step 1: Define frame processing constants
Add constants for frame throttle and stability timing to avoid magic numbers.
- `OmrConstants.frameTargetFps = 10`
- `OmrConstants.frameMinIntervalMs = 100`
- `OmrConstants.markerStabilityMs = 500`

This keeps timing consistent between ScannerBloc and CameraTestPage.

### Step 2: Add explicit 10 FPS throttle in ScannerBloc
Add fields in `ScannerBloc`:
```
DateTime? _lastFrameStart;
final Duration _minFrameInterval = Duration(milliseconds: 100);
```

Add a helper:
```
bool _shouldProcessFrame(DateTime now) {
  if (_isProcessingFrame) return false;
  if (_lastFrameStart != null &&
      now.difference(_lastFrameStart!) < _minFrameInterval) {
    return false;
  }
  _lastFrameStart = now;
  return true;
}
```

Use it at the start of `_processFrame`:
```
final now = DateTime.now();
if (!_shouldProcessFrame(now)) return;
_isProcessingFrame = true;
```

This guarantees a hard 10 FPS ceiling even if processing is fast.

### Step 3: Gate frame processing by scanner state
Process frames only when the UI is in `ScannerPreviewing` or `ScannerAligning`.
```
if (state is! ScannerPreviewing && state is! ScannerAligning) return;
```

This avoids unnecessary work if the stream is still active during capturing or after errors.

### Step 4: Harden CameraImage conversion
Ensure `CameraService.convertCameraImageToBytes` handles row padding for BGRA:
```
static Uint8List _convertBGRA8888ToBytes(CameraImage image) {
  final plane = image.planes[0];
  final bytesPerRow = plane.bytesPerRow;
  final bytesPerPixel = plane.bytesPerPixel ?? 4;
  final width = image.width;
  final height = image.height;

  if (bytesPerRow == width * bytesPerPixel) {
    return Uint8List.fromList(plane.bytes);
  }

  final result = Uint8List(width * height * bytesPerPixel);
  int offset = 0;
  for (int row = 0; row < height; row++) {
    final start = row * bytesPerRow;
    result.setRange(
      offset,
      offset + width * bytesPerPixel,
      plane.bytes,
      start,
    );
    offset += width * bytesPerPixel;
  }
  return result;
}
```

Add optional validation in `ImagePreprocessor.createMatFromPixels` to guard against mismatched byte lengths.

### Step 5: Maintain Mat lifecycle and detection pipeline
Keep the current frame processing pipeline but ensure all Mat objects are disposed:
1. Convert `CameraImage` to bytes.
2. `ImagePreprocessor.createMatFromPixels(...)`.
3. `ImagePreprocessor.preprocess(...)` for grayscale.
4. `MarkerDetector.detect(grayscale)`.

On success, dispatch:
```
if (!isClosed) add(ScannerMarkersUpdated(detectionResult: result));
```

### Step 6: Robust stability timer
Add a `DateTime? _lastAllMarkersSeenAt` field and update it whenever `allMarkersFound` is true.
- Start the 500ms timer on the first full-detection frame.
- When the timer fires, verify:
  - state is still `ScannerAligning`
  - `now.difference(_lastAllMarkersSeenAt) < _stabilityDuration + grace`
- Only then dispatch `ScannerStabilityAchieved`.

On marker loss, cancel the timer and clear `_lastAllMarkersSeenAt`.

This prevents a capture trigger if markers were lost just before the timer fires.

### Step 7: Keep cleanup consistent
Ensure `_cleanup()` cancels:
- `_frameSubscription`
- `_stabilityTimer`
- resets `_lastFrameStart` and `_lastAllMarkersSeenAt`

This avoids leaking timers or continuing detection after errors.

### Step 8 (Optional): Share throttle in CameraTestPage
If desired, move throttle logic into a small helper (e.g., `FrameLimiter`) so CameraTestPage and ScannerBloc stay in sync.

## Testing and Validation

### Unit Tests
- Add a small helper class (or private method tests) to verify:
  - Frames are skipped when `<100ms` apart.
  - `_isProcessingFrame` blocks concurrent processing.
  - Stability timer does not trigger after marker loss.

### BLoC Tests
Update `test/features/omr/presentation/bloc/scanner_bloc_test.dart`:
- Simulate marker updates and verify transition from Previewing -> Aligning.
- Simulate marker loss before timer fires; ensure no capture is triggered.

### Device Validation
- Android: confirm YUV420 conversion works and detection is stable at ~10 FPS.
- iOS: confirm BGRA conversion with row padding works.
- Observe alignment overlay transitions and auto-capture timing.

## Done When
- Frame processing runs at ~10 FPS with no backlog.
- Marker detection updates `ScannerPreviewing/ScannerAligning`.
- Auto-capture triggers only after 500ms of stable detection.
- Works on both Android (YUV) and iOS (BGRA) without crashes or memory leaks.
