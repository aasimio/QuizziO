# Task 6.4: Performance Profiling & Optimization — Execution Plan

> **Reference**: Development-Plan-v2_3.md (Task 6.4), PRD.md (Section 6.1 NFR-P)
> **Created**: 2025-12-26
> **Status**: Planning Complete

---

## 1. Executive Summary

This document provides a detailed execution plan for Task 6.4 Performance Profiling & Optimization. The goal is to measure and validate all PRD performance requirements (NFR-P-01 through NFR-P-04), then optimize any areas that miss targets.

### Target Metrics (PRD 6.1)

| ID | Requirement | Target | Measurement |
|----|-------------|--------|-------------|
| NFR-P-01 | Full scan pipeline | < 500ms | Capture to result display |
| NFR-P-02 | Preview marker detection | < 100ms/frame | Per-frame processing |
| NFR-P-03 | App cold start | < 3 seconds | Launch to camera ready |
| NFR-P-04 | Memory usage during scan | < 200MB | Peak allocation |

---

## 2. Current State Analysis

### 2.1 Existing Instrumentation

**OmrPipeline** (`lib/features/omr/services/omr_scanner_service.dart`):
- Has single `Stopwatch` measuring total pipeline time
- Returns `processingTimeMs` in `OmrResult`
- No per-step breakdown

**ScannerBloc** (`lib/features/omr/presentation/bloc/scanner_bloc.dart`):
- Tracks `stabilityMs` for alignment timing
- No frame processing time measurement
- No memory monitoring

**Cold Start** (`lib/main.dart`):
- No timing instrumentation
- Hive initialization is synchronous/blocking
- Camera init is on-demand (lazy)

### 2.2 Identified Bottlenecks

1. **Duplicate Marker Detection**: `_extractNameRegion()` (lines 589-658) re-runs full marker detection after the main pipeline already detected markers. Potential 100-200ms savings.

2. **Frame Processing Loop**: Runs at 10 FPS with no timing visibility into individual steps.

3. **Bubble Reading Loop**: O(questions × options) iterations with per-ROI Mat allocation.

---

## 3. Implementation Plan

### 3.1 Phase 1: Create Profiling Infrastructure

#### 3.1.1 PerformanceProfiler Service

**File**: `lib/core/services/performance_profiler.dart`

```dart
/// Key features:
/// - Conditional compilation (disabled in release builds)
/// - Named metric types aligned with PRD NFR targets
/// - Session-based collection with statistical analysis
/// - JSON export for external analysis tools
/// - Built-in NFR target validation

enum MetricType {
  // NFR-P-01: Scan Pipeline
  pipelineDecode,
  pipelinePreprocess,
  pipelineDetectMarkers,
  pipelineGetCorners,
  pipelineTransform,
  pipelineReadBubbles,
  pipelineThreshold,
  pipelineExtractAnswers,
  pipelineTotal,

  // NFR-P-02: Frame Processing
  frameConversion,
  frameMatCreation,
  framePreprocess,
  frameMarkerDetection,
  frameTotal,

  // NFR-P-03: Cold Start
  coldStartBinding,
  coldStartDI,
  coldStartHiveInit,
  coldStartBoxOpen,
  coldStartCameraInit,
  coldStartMarkerDetectorInit,
  coldStartTotal,

  // NFR-P-04: Memory
  memoryBaseline,
  memoryPeakScan,
  memoryCurrent,
}

class PerformanceProfiler {
  // Singleton with conditional no-op in release
  bool get isEnabled => !kReleaseMode;

  void startSession(String id);
  void endSession();

  void startTimer(MetricType metric);
  int stopTimer(MetricType metric);  // Returns elapsed ms

  T measure<T>(MetricType metric, T Function() op);
  Future<T> measureAsync<T>(MetricType metric, Future<T> Function() op);

  void sampleMemory({String? context});

  ProfilingSession? get currentSession;
  Map<String, dynamic> exportData();
  Map<String, bool> validateTargets();
}
```

**API Usage Pattern**:
```dart
// Wrap synchronous operation
final result = profiler.measure(MetricType.pipelineDecode, () {
  return _preprocessor.decodeImage(imageBytes);
});

// Wrap async operation
final processed = await profiler.measureAsync(MetricType.pipelinePreprocess, () {
  return _preprocessor.preprocess(mat);
});

// Manual timing for complex flows
profiler.startTimer(MetricType.pipelineTotal);
try {
  // ... multiple steps ...
} finally {
  final totalMs = profiler.stopTimer(MetricType.pipelineTotal);
  developer.log('Pipeline completed in ${totalMs}ms');
}
```

#### 3.1.2 Performance Constants

**File**: `lib/core/constants/performance_constants.dart`

```dart
class PerformanceConstants {
  PerformanceConstants._();

  // NFR-P-01: Scan Pipeline Targets (ms)
  static const int pipelineTotalTarget = 500;
  static const int pipelineDecodeTarget = 50;
  static const int pipelinePreprocessTarget = 80;
  static const int pipelineDetectMarkersTarget = 60;
  static const int pipelineTransformTarget = 50;
  static const int pipelineReadBubblesTarget = 100;
  static const int pipelineThresholdTarget = 20;
  static const int pipelineExtractTarget = 20;

  // NFR-P-02: Frame Processing Targets (ms)
  static const int frameProcessingTarget = 100;
  static const int frameConversionTarget = 10;
  static const int framePreprocessTarget = 40;
  static const int frameMarkerDetectionTarget = 50;

  // NFR-P-03: Cold Start Targets (ms)
  static const int coldStartTotalTarget = 3000;
  static const int coldStartHiveTarget = 500;
  static const int coldStartCameraTarget = 1500;

  // NFR-P-04: Memory Targets (bytes)
  static const int memoryPeakTargetBytes = 200 * 1024 * 1024;  // 200MB

  // Profiling Configuration
  static const int frameSampleInterval = 10;  // Profile every Nth frame
}
```

---

### 3.2 Phase 2: Instrument Scan Pipeline (6.4.1)

**File**: `lib/features/omr/services/omr_scanner_service.dart`

#### Instrumentation Points

| Step | Current Location | Metric to Measure |
|------|------------------|-------------------|
| Decode image | Line 88 | `pipelineDecode` |
| Preprocess | Line 91 | `pipelinePreprocess` |
| Detect markers | Line 96 | `pipelineDetectMarkers` |
| Get corner points | Lines 109-110 | `pipelineGetCorners` |
| Perspective transform | Lines 123-129 | `pipelineTransform` |
| Read bubbles | Lines 134-137 | `pipelineReadBubbles` |
| Calculate threshold | Lines 142-143 | `pipelineThreshold` |
| Extract answers | Lines 147-150 | `pipelineExtractAnswers` |
| **Total** | Lines 80-158 | `pipelineTotal` |

#### Modified process() Method

```dart
Future<OmrResult> process({
  required Uint8List imageBytes,
  required int templateWidth,
  required int templateHeight,
  required Map<String, List<Rect>> bubblePositions,
  int edgePaddingPx = 90,
}) async {
  profiler.startSession('omr_pipeline_${DateTime.now().millisecondsSinceEpoch}');
  profiler.startTimer(MetricType.pipelineTotal);

  cv.Mat? mat;
  cv.Mat? processed;
  cv.Mat? aligned;

  try {
    // Step 1: Decode
    mat = profiler.measure(MetricType.pipelineDecode, () {
      return _preprocessor.decodeImage(imageBytes);
    });

    // Step 2: Preprocess
    processed = await profiler.measureAsync(MetricType.pipelinePreprocess, () {
      return _preprocessor.preprocess(mat!);
    });
    mat.dispose();
    mat = null;

    // Step 3: Detect markers
    final markerResult = await profiler.measureAsync(MetricType.pipelineDetectMarkers, () {
      return _markerDetector.detect(processed!);
    });

    if (!markerResult.allMarkersFound) {
      throw OmrException('Could not detect all 4 corner markers');
    }

    // Step 4: Get corner points
    final cornerPoints = profiler.measure(MetricType.pipelineGetCorners, () {
      return _markerDetector.getCornerPointsForTransform(processed!);
    });

    if (cornerPoints == null || cornerPoints.length != 4) {
      throw OmrException('Could not get corner points for transform');
    }

    // Step 5: Perspective transform
    aligned = await profiler.measureAsync(MetricType.pipelineTransform, () {
      return _transformer.transform(
        processed!,
        cornerPoints,
        templateWidth,
        templateHeight,
        edgePaddingPx: edgePaddingPx,
      );
    });
    processed.dispose();
    processed = null;

    // Step 6: Read bubbles
    final bubbleResult = profiler.measure(MetricType.pipelineReadBubbles, () {
      return _bubbleReader.readAllBubbles(aligned!, bubblePositions);
    });
    aligned.dispose();
    aligned = null;

    // Step 7: Calculate threshold
    final thresholdResult = profiler.measure(MetricType.pipelineThreshold, () {
      return _thresholdCalculator.calculate(bubbleResult.allValues);
    });

    // Step 8: Extract answers
    final answers = profiler.measure(MetricType.pipelineExtractAnswers, () {
      return _thresholdCalculator.extractAnswers(
        bubbleResult.bubbleValues,
        thresholdResult.threshold,
      );
    });

    final totalMs = profiler.stopTimer(MetricType.pipelineTotal);
    final session = profiler.endSession();

    return OmrResult(
      success: true,
      answers: answers,
      markerResult: markerResult,
      thresholdResult: thresholdResult,
      processingTimeMs: totalMs,
      stepTimings: session?.exportStepTimings(),  // New field
    );
  } catch (e, stackTrace) {
    mat?.dispose();
    processed?.dispose();
    aligned?.dispose();
    profiler.stopTimer(MetricType.pipelineTotal);
    profiler.endSession();
    rethrow;
  }
}
```

---

### 3.3 Phase 3: Instrument Frame Processing (6.4.2)

**File**: `lib/features/omr/presentation/bloc/scanner_bloc.dart`

#### Frame Sampling Strategy

Profile every 10th frame to minimize overhead:

```dart
int _frameCount = 0;

Future<void> _processFrame(CameraImage image) async {
  final shouldProfile = profiler.isEnabled && (_frameCount++ % 10 == 0);

  if (shouldProfile) {
    profiler.startTimer(MetricType.frameTotal);
  }

  try {
    // Step 1: Convert camera image to bytes
    final Uint8List bytes;
    if (shouldProfile) profiler.startTimer(MetricType.frameConversion);
    bytes = CameraService.convertCameraImageToBytes(image);
    if (shouldProfile) profiler.stopTimer(MetricType.frameConversion);

    // Step 2: Create Mat from pixels
    final bool isBGRA = Platform.isIOS;
    cv.Mat? mat;
    if (shouldProfile) profiler.startTimer(MetricType.frameMatCreation);
    mat = _preprocessor.createMatFromPixels(
      bytes,
      image.width,
      image.height,
      isBGRA,
    );
    if (shouldProfile) profiler.stopTimer(MetricType.frameMatCreation);

    try {
      // Step 3: Preprocess to grayscale
      cv.Mat? grayscale;
      if (shouldProfile) profiler.startTimer(MetricType.framePreprocess);
      grayscale = await _preprocessor.preprocess(mat);
      if (shouldProfile) profiler.stopTimer(MetricType.framePreprocess);

      try {
        // Step 4: Detect markers
        if (shouldProfile) profiler.startTimer(MetricType.frameMarkerDetection);
        final result = await _markerDetector.detect(grayscale);
        if (shouldProfile) profiler.stopTimer(MetricType.frameMarkerDetection);

        // Emit result...
        add(ScannerMarkersUpdated(result));
      } finally {
        grayscale.dispose();
      }
    } finally {
      mat.dispose();
    }
  } finally {
    if (shouldProfile) {
      final frameMs = profiler.stopTimer(MetricType.frameTotal);
      developer.log('Frame processing: ${frameMs}ms', name: 'Profiler');
    }
  }
}
```

---

### 3.4 Phase 4: Instrument Cold Start (6.4.3)

**File**: `lib/main.dart`

```dart
Future<void> main() async {
  profiler.startSession('cold_start');
  profiler.startTimer(MetricType.coldStartTotal);

  // Flutter binding
  profiler.startTimer(MetricType.coldStartBinding);
  WidgetsFlutterBinding.ensureInitialized();
  profiler.stopTimer(MetricType.coldStartBinding);

  // DI configuration
  profiler.startTimer(MetricType.coldStartDI);
  configureDependencies();
  profiler.stopTimer(MetricType.coldStartDI);

  // Hive initialization
  profiler.startTimer(MetricType.coldStartHiveInit);
  await Hive.initFlutter();
  Hive.registerAdapter(QuizModelAdapter());
  Hive.registerAdapter(ScanResultModelAdapter());
  profiler.stopTimer(MetricType.coldStartHiveInit);

  // Box opening
  profiler.startTimer(MetricType.coldStartBoxOpen);
  await Future.wait([
    Hive.openBox<QuizModel>(HiveBoxes.quizzes),
    Hive.openBox<ScanResultModel>(HiveBoxes.scanResults),
  ]);
  profiler.stopTimer(MetricType.coldStartBoxOpen);

  final coldStartMs = profiler.stopTimer(MetricType.coldStartTotal);
  developer.log('Cold start to runApp: ${coldStartMs}ms', name: 'Profiler');

  runApp(const QuizziOApp());

  // Measure first frame
  WidgetsBinding.instance.addPostFrameCallback((_) {
    developer.log('First frame rendered', name: 'Profiler');
    profiler.endSession();
  });
}
```

**Additional Cold Start Instrumentation**:

**CameraService.initialize()** (`lib/core/services/camera_service.dart`):
```dart
Future<void> initialize() async {
  profiler.startTimer(MetricType.coldStartCameraInit);
  try {
    final cameras = await availableCameras();
    // ... camera setup ...
    await _controller!.initialize();
    await _controller!.lockCaptureOrientation(DeviceOrientation.portraitUp);
  } finally {
    profiler.stopTimer(MetricType.coldStartCameraInit);
  }
}
```

**MarkerDetector.initialize()** (`lib/features/omr/services/marker_detector.dart`):
```dart
Future<void> initialize() async {
  profiler.startTimer(MetricType.coldStartMarkerDetectorInit);
  try {
    _dictionary = cv.ArucoDictionary.predefined(
      cv.PredefinedDictionaryType.DICT_4X4_50,
    );
    _params = cv.ArucoDetectorParameters.empty();
    _detector = cv.ArucoDetector.create(_dictionary!, _params!);
  } finally {
    profiler.stopTimer(MetricType.coldStartMarkerDetectorInit);
  }
}
```

---

### 3.5 Phase 5: Add Memory Sampling (6.4.4)

**File**: `lib/features/omr/presentation/bloc/scanner_bloc.dart`

#### Strategic Memory Sampling Points

```dart
// In _onInitCamera (after camera init)
Future<void> _onInitCamera(ScannerInitCamera event, Emitter emit) async {
  // ... camera init ...
  profiler.sampleMemory(context: 'after_camera_init');
  // ...
}

// In _onImageCaptured (during processing)
Future<void> _onImageCaptured(ScannerImageCaptured event, Emitter emit) async {
  profiler.sampleMemory(context: 'before_pipeline');

  // ... pipeline processing ...

  profiler.sampleMemory(context: 'after_pipeline');

  // ... name region extraction ...

  profiler.sampleMemory(context: 'after_name_extraction');

  // ... save to repository ...

  profiler.sampleMemory(context: 'after_save');
}
```

**File**: `lib/features/omr/services/omr_scanner_service.dart`

```dart
// After major allocations in process()
// Step 2: After preprocess
profiler.sampleMemory(context: 'after_preprocess_mat');

// Step 5: After transform
profiler.sampleMemory(context: 'after_transform_mat');

// After disposals
mat.dispose();
profiler.sampleMemory(context: 'after_mat_dispose');
```

---

## 4. Optimization Strategies (6.4.5)

### 4.1 If Pipeline > 500ms

#### Priority 1: Eliminate Duplicate Marker Detection

**Issue**: `_extractNameRegion()` runs full marker detection again.

**Solution**: Extract name region during main pipeline before disposing aligned image.

**Modified OmrPipeline.process()**:
```dart
// After perspective transform, before disposing aligned:
final nameRegionBytes = _extractNameRegionFromAligned(
  aligned,
  template.nameRegionX,
  template.nameRegionY,
  template.nameRegionWidth,
  template.nameRegionHeight,
);

return OmrResult(
  // ... existing fields ...
  nameRegionBytes: nameRegionBytes,  // New field
);
```

**Expected Savings**: 100-200ms

#### Priority 2: Lazy CLAHE Creation

**Current**: Creates new CLAHE object per `preprocess()` call.

**Optimized**: Create once, reuse.

```dart
@lazySingleton
class ImagePreprocessor {
  cv.CLAHE? _clahe;

  cv.CLAHE get clahe => _clahe ??= cv.createCLAHE(
    clipLimit: 2.0,
    tileGridSize: (8, 8),
  );
}
```

**Expected Savings**: 10-20ms

#### Priority 3: Buffer Reuse in BubbleReader

**Current**: Creates new `cv.Rect` and ROI for each bubble.

**Optimized**: Pre-allocate and reuse.

**Expected Savings**: 20-50ms

### 4.2 If Frame Processing > 100ms

#### Reduce Preview Resolution

```dart
// In CameraService.initialize()
_controller = CameraController(
  camera,
  ResolutionPreset.medium,  // Was: high
  enableAudio: false,
);
```

#### Skip CLAHE for Preview

ArUco detection works on simple grayscale without CLAHE:

```dart
// In _processFrame()
grayscale = await _preprocessor.toGrayscale(mat);  // Simpler, faster
```

### 4.3 If Cold Start > 3s

#### Parallelize Hive Box Opening

Already implemented in Phase 4 using `Future.wait()`.

#### Defer MarkerDetector Init

Move initialization to first scan instead of camera init:

```dart
// In ScannerBloc._onInitCamera()
// Don't call _markerDetector.initialize() here

// In _processFrame() or _onStabilityAchieved()
if (!_markerDetector.isInitialized) {
  await _markerDetector.initialize();
}
```

### 4.4 If Memory > 200MB

#### Verify Mat Disposal

Add debug assertions:

```dart
// In OmrPipeline.process()
assert(() {
  developer.log('Mat disposed: ${mat?.isDisposed}', name: 'MemoryDebug');
  return true;
}());
```

#### Buffer Pooling for Frame Conversion

```dart
class ByteBufferPool {
  final List<Uint8List> _pool = [];
  final int _maxSize = 3;

  Uint8List acquire(int size) {
    if (_pool.isNotEmpty && _pool.last.length >= size) {
      return _pool.removeLast();
    }
    return Uint8List(size);
  }

  void release(Uint8List buffer) {
    if (_pool.length < _maxSize) {
      _pool.add(buffer);
    }
  }
}
```

---

## 5. Validation Procedure (6.4.6)

### 5.1 Test Devices

| Priority | Device | Android Version | RAM | Camera |
|----------|--------|-----------------|-----|--------|
| P0 | Pixel 4a | Android 13 | 6GB | 12MP |
| P0 | iPhone 12 | iOS 17 | 4GB | 12MP |
| P1 | Samsung A52 | Android 12 | 6GB | 64MP |
| P2 | Low-end (API 24) | Android 7.0 | 2-3GB | 8MP |

### 5.2 Test Procedure

1. **Cold Start Test** (5 runs, calculate average):
   - Force stop app completely
   - Launch via home screen icon
   - Measure time to QuizzesPage render
   - Navigate to ScanPapersPage
   - Measure time to camera preview ready

2. **Pipeline Test** (10 scans per template):
   - Use 10q, 20q, 50q test sheets
   - Record per-step timing via profiler
   - Calculate min, max, avg, P50, P95

3. **Frame Rate Test** (60 seconds continuous):
   - Navigate to scan screen
   - Let preview run without scanning
   - Collect frame processing times
   - Calculate average FPS

4. **Memory Test** (10 consecutive scans):
   - Use Android Studio Profiler or Xcode Instruments
   - Record baseline before first scan
   - Record peak during each scan
   - Verify no memory growth (leak detection)

5. **Low-End Validation** (API 24 device):
   - Run all above tests
   - Document any degradation
   - Verify no OOM crashes or ANR

### 5.3 Acceptance Criteria

| Metric | Target | Pass Criteria |
|--------|--------|---------------|
| Pipeline | < 500ms | P95 < 500ms |
| Frame | < 100ms | P95 < 100ms |
| Cold Start | < 3000ms | Max < 3000ms |
| Memory | < 200MB | Peak < 200MB |

---

## 6. Deliverables

### 6.1 New Files

| File | Purpose |
|------|---------|
| `lib/core/services/performance_profiler.dart` | Profiling infrastructure |
| `lib/core/constants/performance_constants.dart` | NFR targets and thresholds |

### 6.2 Modified Files

| File | Changes |
|------|---------|
| `lib/features/omr/services/omr_scanner_service.dart` | Step-by-step timing |
| `lib/features/omr/presentation/bloc/scanner_bloc.dart` | Frame timing, memory sampling |
| `lib/main.dart` | Cold start timing |
| `lib/core/services/camera_service.dart` | Camera init timing |
| `lib/features/omr/services/marker_detector.dart` | Init timing |
| `lib/injection.dart` | Register PerformanceProfiler |

### 6.3 Documentation

| Document | Purpose |
|----------|---------|
| `Tasks/6.4_results.md` | Profiling results and metrics |
| Device compatibility matrix | Test results per device |

---

## 7. Implementation Checklist

- [x] **Step 1**: Create `PerformanceProfiler` service
- [x] **Step 2**: Create `PerformanceConstants` file
- [x] **Step 3**: Register profiler in DI (debug/profile only)
- [x] **Step 4**: Instrument `OmrPipeline.process()` (6.4.1)
- [x] **Step 5**: Instrument `ScannerBloc._processFrame()` (6.4.2)
- [x] **Step 6**: Instrument `main.dart` cold start (6.4.3)
- [x] **Step 7**: Instrument camera and marker detector init
- [x] **Step 8**: Add memory sampling points (6.4.4)
- [x] **Step 9**: Apply optimizations (6.4.5) - see Applied Optimizations below
- [x] **Step 10**: Validate code compiles with `flutter analyze`
- [x] **Step 11**: Document optimizations in Development Plan

---

## 8. Applied Optimizations (6.4.5)

The following optimizations were implemented based on code analysis:

### 8.1 CLAHE Object Caching (~30-50ms savings)
**File**: `lib/features/omr/services/image_preprocessor.dart`
- Added `_clahe` member variable for cached CLAHE object
- CLAHE is now created once on first use, reused for all subsequent calls
- Added `dispose()` method to clean up cached resources

### 8.2 Lightweight Preview Preprocessing (~20-40ms savings per frame)
**File**: `lib/features/omr/services/image_preprocessor.dart`
- Added `preprocessForPreview()` method that skips CLAHE and normalization
- ArUco marker detection works well on simple grayscale images
- Full preprocessing (`preprocess()`) reserved for captured images

**File**: `lib/features/omr/presentation/bloc/scanner_bloc.dart`
- Updated `_processFrame()` to use `preprocessForPreview()` instead of `preprocess()`

### 8.3 Cached Marker Detection (~100-200ms savings)
**File**: `lib/features/omr/services/marker_detector.dart`
- Added `_lastDetectedMarkers` cache that stores detection results
- Added `getCornerPointsFromCachedDetection()` method to retrieve corners without re-running detection
- Added `clearCache()` method for explicit cache clearing

**File**: `lib/features/omr/services/omr_scanner_service.dart`
- Updated to use `getCornerPointsFromCachedDetection()` instead of `getCornerPointsForTransform()`

**File**: `lib/features/omr/presentation/bloc/scanner_bloc.dart`
- Updated `_extractNameRegion()` to use `getCornerPointsFromCachedDetection()`

### 8.4 Estimated Total Savings
| Optimization | Estimated Savings |
|--------------|-------------------|
| CLAHE caching | 30-50ms per pipeline call |
| Preview preprocessing | 20-40ms per frame (10 FPS = 200-400ms/sec) |
| Cached marker detection | 100-200ms per capture (eliminates 2 duplicate calls) |
| **Total per scan** | **~150-290ms** |

---

## 9. Risk Mitigation

| Risk | Mitigation |
|------|------------|
| Profiling overhead affects measurements | Use conditional compilation, sample every Nth frame |
| Low-end device unavailable | Use Android emulator with API 24 for initial validation |
| opencv_dart memory not visible | Use Timeline API events for correlation |
| Results vary between runs | Take P95 over 10+ runs for each metric |

---

## 10. Validation Notes (6.4.6)

For low-end device validation:
- Use Android emulator with API 24 minimum
- Run `flutter run --profile` to collect metrics
- Use `PerformanceProfiler.validateTargets()` to check against PRD NFR-P requirements
- Check `exportData()` for detailed breakdown

---

*Plan created: 2025-12-26*
*Instrumentation completed: 2025-12-26*
*Optimizations applied: 2025-12-26*
*Status: Complete - Ready for device validation*
